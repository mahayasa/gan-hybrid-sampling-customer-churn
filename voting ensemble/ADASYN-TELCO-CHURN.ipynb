{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fyiob-gotxeGbgw_B6UWCKtHywKxyPxk","timestamp":1681279484154}],"authorship_tag":"ABX9TyPnBcp4U5neibwLfrEDHZr6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"md_-JptW5DCZ","executionInfo":{"status":"ok","timestamp":1681285761854,"user_tz":-420,"elapsed":20356,"user":{"displayName":"mahayasa adiputra","userId":"06368761074860067181"}},"outputId":"043992ca-6b13-4da7-e151-a5dad956e1a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.928532632437933, 0.928376225604481]\n","F1 score: 0.849\n","STD F1 Score: 0.007\n"]}],"source":["# ORIGINAL CODE : https://machinelearningmastery.com/weighted-average-ensemble-with-python/\n","# By Jason Brownlee - MAY 2021\n","\n","# Modifed by MAHAYASA ADIPUTRA - OCT 2022\n","import time\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix ,accuracy_score\n","from sklearn.metrics import roc_curve, roc_auc_score\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from imblearn.over_sampling import ADASYN\n","from imblearn.combine import SMOTEENN\n","from sklearn.preprocessing import LabelEncoder\n","import sklearn.metrics as mt\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","import pandas as pd\n","import numpy as np\n","from numpy import mean\n","from numpy import std\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.ensemble import VotingClassifier\n","le = LabelEncoder()\n","start_time = time.time()\n","from imblearn.under_sampling import EditedNearestNeighbours\n","from imblearn.under_sampling import TomekLinks\n","from imblearn.under_sampling import NeighbourhoodCleaningRule\n","# get the dataset\n","# Importing the dataset\n","dataset=pd.read_csv('https://snow.co.id/customerchurn/data/telco_churn.csv')\n","dataset=dataset.dropna()\n","#dataset=dataset.fillna(0)\n","\n","#transform data into numeric value\n","dataset['Partner']=le.fit_transform(dataset['Partner'])\n","dataset['Dependents']=le.fit_transform(dataset['Dependents'])\n","dataset['PhoneService']=le.fit_transform(dataset['PhoneService'])\n","dataset['MultipleLines']=le.fit_transform(dataset['MultipleLines'])\n","dataset['InternetService']=le.fit_transform(dataset['InternetService'])\n","dataset['OnlineSecurity']=le.fit_transform(dataset['OnlineSecurity'])\n","dataset['DeviceProtection']=le.fit_transform(dataset['DeviceProtection'])\n","dataset['TechSupport']=le.fit_transform(dataset['TechSupport'])\n","dataset['StreamingTV']=le.fit_transform(dataset['StreamingTV'])\n","dataset['StreamingMovies']=le.fit_transform(dataset['StreamingMovies'])\n","dataset['Contract']=le.fit_transform(dataset['Contract'])\n","dataset['PaperlessBilling']=le.fit_transform(dataset['PaperlessBilling'])\n","dataset['PaymentMethod']=le.fit_transform(dataset['PaymentMethod'])\n","dataset['gender']=le.fit_transform(dataset['gender'])\n","dataset['OnlineBackup']=le.fit_transform(dataset['OnlineBackup'])\n","\n","#filling missing value with mean\n","dataset['TotalCharges'].replace(to_replace = 0, value = dataset['TotalCharges'].mean(), inplace=True)\n","X=dataset.drop(['Churn','customerID'],axis=1)\n","y=dataset[\"Churn\"]\n","y = le.fit_transform(y)\n","\n","# apply ADASYN to the dataset\n","adasyn = ADASYN()\n","X, y = adasyn.fit_resample(X, y)\n","#enn = EditedNearestNeighbours(n_neighbors=3)\n","#X, y = enn.fit_resample(X, y)\n","#ncr = NeighbourhoodCleaningRule(n_neighbors=5, kind_sel='all')\n","#X, y = ncr.fit_resample(X, y)\n","tomek_links = TomekLinks()\n","X, y = tomek_links.fit_resample(X, y)\n","\n","#kfold cross validation\n","cv = KFold(n_splits=5, random_state=1, shuffle=True)\n","# get a list of base models\n","def get_models():\n","\tmodels = list()\n","\tmodels.append(('xb', XGBClassifier(colsample_bytree=0.6, max_depth = 5, gamma=1.5, min_child_weight=5)))\n","\tmodels.append(('rf', RandomForestClassifier(n_estimators =100, criterion = 'gini', random_state = 0)))\n","#\tmodels.append(('ab', AdaBoostClassifier(n_estimators=100,learning_rate=0.1,algorithm='SAMME.R')))\n","\treturn models\n"," \n","# evaluate each base model\n","def evaluate_models(models, X,y):\n","\t# fit and evaluate the models\n","\tscores = list()\n","\tfor name, model in models:\n","\t\t# evaluate the model\n","\t\tacc=cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n","\t\t# store the performance\n","\t\tscores.append(mean(acc))\n","\t\t# report model performance\n","\treturn scores\n","\n","\n","\n","# create the base models\n","models = get_models()\n","# fit and evaluate each model\n","scores = evaluate_models(models, X,y)\n","print(scores)\n","# create the ensemble\n","ensemble = VotingClassifier(estimators=models, voting='soft', weights=scores)\n","score=cross_val_score(ensemble, X, y, scoring='f1', cv=cv, n_jobs=-1)\n","print('F1 score: %.3f' % (mean(score)))\n","print('STD F1 Score: %.3f' % (std(score)))"]},{"cell_type":"code","source":["rc=cross_val_score(ensemble, X, y, scoring='recall', cv=cv, n_jobs=-1)\n","rc=mean(rc)\n","rc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6EWGFESD5sVN","executionInfo":{"status":"ok","timestamp":1681285768603,"user_tz":-420,"elapsed":6751,"user":{"displayName":"mahayasa adiputra","userId":"06368761074860067181"}},"outputId":"8ec35497-b93a-4b79-994e-915bcd810b8d"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.864464448484697"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["from sklearn.metrics import make_scorer\n","from imblearn.metrics import specificity_score\n","\n","# Define the specificity scorer\n","scorer = make_scorer(specificity_score)\n","\n","# Calculate the cross-validated specificity score\n","sp = cross_val_score(ensemble, X, y, cv=5, scoring=scorer)\n","sp=mean(sp)\n","sp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EhNxMzHoYG3i","executionInfo":{"status":"ok","timestamp":1681285779258,"user_tz":-420,"elapsed":10657,"user":{"displayName":"mahayasa adiputra","userId":"06368761074860067181"}},"outputId":"c2a6e829-54a8-4c71-f2f4-458ae0a19d31"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8424814285313824"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["auc=cross_val_score(ensemble, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n","auc=mean(auc)\n","auc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FeBrpgdaYJSN","executionInfo":{"status":"ok","timestamp":1681285788184,"user_tz":-420,"elapsed":8928,"user":{"displayName":"mahayasa adiputra","userId":"06368761074860067181"}},"outputId":"0d005210-56f8-446e-8c10-a6be94f513ac"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9347882709051889"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["import math\n","\n","gmean=rc*sp\n","sqrtg = math.sqrt(gmean)\n","sqrtg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ay6ZomycYKrj","executionInfo":{"status":"ok","timestamp":1681285788184,"user_tz":-420,"elapsed":4,"user":{"displayName":"mahayasa adiputra","userId":"06368761074860067181"}},"outputId":"a3b5d164-fe97-4403-9ef4-419b0a19b228"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8534021581142042"]},"metadata":{},"execution_count":54}]}]}